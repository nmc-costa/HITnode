

---

# ğŸ“ ML Pipeline Directory Structure

This codebase follows a node-based architecture where each directory contains reusable nodes that can be composed into ML pipelines.

## ğŸ“ Directory Structure

```
# Phase 1: Business & Data Understanding (CRISP-ML(Q) + AI Integration)
business_understanding/      # Business objectives and stakeholder requirements processing
â”œâ”€â”€ requirements/           # NLP nodes to extract and embed stakeholder requirements from documents
â”œâ”€â”€ constraints/            # Nodes to parse technical/business constraints and create constraint graphs
â”œâ”€â”€ risk_assessment/        # Automated risk analysis nodes using NLP and rule-based systems
â”œâ”€â”€ success_metrics/        # Nodes to extract and formalize business KPIs and success criteria
â”œâ”€â”€ stakeholder_analysis/   # NLP nodes to analyze stakeholder communications and priorities
â”œâ”€â”€ domain_knowledge/       # Nodes to process domain-specific documents and create knowledge graphs
â””â”€â”€ context_extraction/     # Extract and structure business context for LLM applications

data_understanding/          # Data exploration and automated analysis
â”œâ”€â”€ exploratory_analysis/   # Automated EDA nodes with statistical profiling
â”œâ”€â”€ data_quality/          # Data quality assessment and anomaly detection nodes
â”œâ”€â”€ statistics/            # Statistical analysis and distribution modeling nodes
â”œâ”€â”€ hypothesis_generation/ # NLP nodes to generate data-driven hypotheses from initial analysis
â”œâ”€â”€ semantic_analysis/     # Nodes to understand data semantics and relationships
â”œâ”€â”€ metadata_extraction/   # Automated metadata extraction and cataloging nodes
â””â”€â”€ multimodal_analysis/   # Analysis nodes for text, image, audio, and video data

# Phase 2: Data Preparation (CRISP-DM/ML(Q) + LLM Data Processing)
datasets/                    # Data I/O, ingestion, loading, and saving
â”œâ”€â”€ loaders/                # Load data from various sources (CSV, JSON, APIs, databases)
â”œâ”€â”€ savers/                 # Save data to different formats and destinations
â”œâ”€â”€ extractors/             # Extract data from external systems and APIs
â”œâ”€â”€ validators/             # Data quality validation and schema checking
â”œâ”€â”€ huggingface_datasets/   # Hugging Face dataset integration and management
â””â”€â”€ multimodal_loaders/     # Loaders for text, image, audio, video data

preprocessing/               # Data cleaning, transformations, feature engineering
â”œâ”€â”€ cleaners/               # Data cleaning and quality improvement nodes
â”œâ”€â”€ transformers/           # Data type conversions and transformations
â”œâ”€â”€ feature_engineering/    # Feature creation, selection, and extraction
â”œâ”€â”€ normalizers/            # Data normalization and scaling
â”œâ”€â”€ splitters/              # Train/validation/test data splitting
â”œâ”€â”€ text_processors/        # Text preprocessing for NLP and LLM applications
â”œâ”€â”€ tokenizers/             # Tokenization nodes for various models and frameworks
â””â”€â”€ embeddings_prep/        # Prepare data for embedding generation

# Phase 3: Model Engineering (CRISP-ML(Q) + LLM/AI Models)
models/                      # Training, fitting, prediction, and inference
â”œâ”€â”€ trainers/               # Model training and fitting nodes
â”œâ”€â”€ predictors/             # Prediction and inference nodes
â”œâ”€â”€ tuners/                 # Hyperparameter tuning and optimization
â”œâ”€â”€ architectures/          # Model architecture definitions and configurations
â”œâ”€â”€ ensembles/             # Ensemble methods and model combination
â”œâ”€â”€ versioning/            # Model versioning and comparison
â”œâ”€â”€ huggingface_models/    # Hugging Face model integration and fine-tuning
â”œâ”€â”€ llm_models/            # Large language model implementations and wrappers
â”œâ”€â”€ embedding_models/      # Embedding model implementations (text, image, multimodal)
â”œâ”€â”€ multimodal_models/     # Multi-modal AI models (vision-language, etc.)
â””â”€â”€ custom_architectures/  # Custom neural network architectures

# LLM/AI Application Components
llm_applications/            # LLM-powered application components
â”œâ”€â”€ prompts/               # Prompt engineering and template management
â”‚   â”œâ”€â”€ templates/         # Reusable prompt templates
â”‚   â”œâ”€â”€ chains/            # Prompt chaining strategies
â”‚   â”œâ”€â”€ few_shot/          # Few-shot learning prompts
â”‚   â””â”€â”€ optimization/      # Prompt optimization and testing
â”œâ”€â”€ agents/                # AI agent implementations and workflows
â”‚   â”œâ”€â”€ autonomous/        # Autonomous agent systems
â”‚   â”œâ”€â”€ collaborative/     # Multi-agent collaboration
â”‚   â”œâ”€â”€ tool_using/        # Tool-using agents
â”‚   â””â”€â”€ planning/          # Agent planning and reasoning
â”œâ”€â”€ chains/                # LangChain-style processing chains
â”‚   â”œâ”€â”€ sequential/        # Sequential processing chains
â”‚   â”œâ”€â”€ parallel/          # Parallel processing chains
â”‚   â”œâ”€â”€ conditional/       # Conditional logic chains
â”‚   â””â”€â”€ custom/            # Custom chain implementations
â”œâ”€â”€ tools/                 # AI tools and function calling
â”‚   â”œâ”€â”€ api_tools/         # API interaction tools
â”‚   â”œâ”€â”€ data_tools/        # Data manipulation tools
â”‚   â”œâ”€â”€ search_tools/      # Search and retrieval tools
â”‚   â””â”€â”€ custom_tools/      # Custom tool implementations
â”œâ”€â”€ retrievers/            # Information retrieval systems
â”‚   â”œâ”€â”€ vector_search/     # Vector-based retrieval
â”‚   â”œâ”€â”€ keyword_search/    # Traditional keyword search
â”‚   â”œâ”€â”€ hybrid_search/     # Hybrid retrieval approaches
â”‚   â””â”€â”€ semantic_search/   # Semantic search implementations
â”œâ”€â”€ rag_systems/           # Retrieval Augmented Generation
â”‚   â”œâ”€â”€ retrievers/        # RAG retrieval components
â”‚   â”œâ”€â”€ generators/        # RAG generation components
â”‚   â”œâ”€â”€ rankers/           # Result ranking and reranking
â”‚   â”œâ”€â”€ fusion/            # Multi-source information fusion
â”‚   â””â”€â”€ evaluation/        # RAG system evaluation
â”œâ”€â”€ context_management/    # Context handling and memory
â”‚   â”œâ”€â”€ memory/            # Conversation and session memory
â”‚   â”œâ”€â”€ context_windows/   # Context window management
â”‚   â”œâ”€â”€ summarization/     # Context summarization strategies
â”‚   â””â”€â”€ retrieval/         # Context retrieval mechanisms
â””â”€â”€ mcp_integration/       # Model Context Protocol integration
    â”œâ”€â”€ servers/           # MCP server implementations
    â”œâ”€â”€ clients/           # MCP client implementations
    â”œâ”€â”€ connectors/        # MCP connectors for various tools
    â””â”€â”€ protocols/         # Custom protocol implementations

# Phase 4: Model Evaluation (CRISP-ML(Q) + LLM Evaluation)
evaluation/                  # Unified evaluation, metrics, and analysis
â”œâ”€â”€ metrics/                # Performance metrics (MAE, MSE, F1, AUC, NDCG, BLEU, ROUGE)
â”‚   â”œâ”€â”€regression/             # Regression metrics (MAE, MSE, RMSE, MAPE, RÂ²)
â”‚   â”œâ”€â”€ classification/         # Classification metrics (accuracy, F1, precision, recall, AUC)
â”‚   â”œâ”€â”€ ranking/                # Ranking metrics (NDCG, MAP, MRR)
â”‚   â”œâ”€â”€ custom/                 # Business-specific and domain metrics
scoring/                     # Scoring predictions and business logic
â”‚   â”œâ”€â”€thresholding/           # Threshold-based scoring and classification
â”‚   â”œâ”€â”€ ranking/                # Ranking and percentile-based scoring
â”‚   â”œâ”€â”€ calibration/            # Probability calibration and confidence scoring
â”‚   â”œâ”€â”€ business_rules/         # Business logic and rule-based scoring
â”œâ”€â”€ validation/             # Cross-validation and model validation strategies
â”œâ”€â”€ testing/                # A/B testing and statistical testing nodes
â”œâ”€â”€ explainability/         # Model interpretability (SHAP, LIME, feature importance)
â”œâ”€â”€ comparison/             # Model comparison and benchmarking
â”œâ”€â”€ quality_assurance/      # Quality gates and acceptance criteria
â”œâ”€â”€ stakeholder_review/     # Stakeholder acceptance and sign-off
â”œâ”€â”€ llm_evaluation/         # LLM-specific evaluation methods
â”‚   â”œâ”€â”€ human_eval/        # Human evaluation frameworks
â”‚   â”œâ”€â”€ automated_eval/    # Automated evaluation systems
â”‚   â”œâ”€â”€ bias_testing/      # Bias and fairness evaluation
â”‚   â”œâ”€â”€ safety_testing/    # AI safety and alignment testing
â”‚   â””â”€â”€ prompt_evaluation/ # Prompt effectiveness evaluation
â””â”€â”€ rag_evaluation/         # RAG system evaluation
    â”œâ”€â”€ retrieval_metrics/ # Retrieval quality metrics
    â”œâ”€â”€ generation_metrics/# Generation quality metrics
    â”œâ”€â”€ end_to_end/        # End-to-end RAG evaluation
    â””â”€â”€ human_feedback/    # Human feedback integration

# Phase 5: Model Deployment (CRISP-ML(Q) + LLM Deployment)
deployment/                  # Production deployment and serving
â”œâ”€â”€ serving/                # Real-time and batch serving endpoints
â”œâ”€â”€ infrastructure/         # Infrastructure as code and deployment configs
â”œâ”€â”€ pipelines/             # Automated deployment pipelines
â”œâ”€â”€ rollback/              # Rollback and recovery mechanisms
â”œâ”€â”€ security/               # Security configurations and access controls
â”œâ”€â”€ llm_serving/           # LLM-specific serving infrastructure
â”‚   â”œâ”€â”€ api_endpoints/     # LLM API endpoint implementations
â”‚   â”œâ”€â”€ streaming/         # Streaming response handling
â”‚   â”œâ”€â”€ batching/          # Batch processing systems
â”‚   â””â”€â”€ load_balancing/    # Load balancing for LLM services
â”œâ”€â”€ agent_deployment/      # AI agent deployment systems
â”‚   â”œâ”€â”€ orchestration/     # Agent orchestration platforms
â”‚   â”œâ”€â”€ workflow_engines/  # Workflow execution engines
â”‚   â”œâ”€â”€ scheduling/        # Agent task scheduling
â”‚   â””â”€â”€ monitoring/        # Agent performance monitoring
â””â”€â”€ edge_deployment/       # Edge and mobile deployment
    â”œâ”€â”€ optimization/      # Model optimization for edge
    â”œâ”€â”€ quantization/      # Model quantization techniques
    â”œâ”€â”€ compression/       # Model compression methods
    â””â”€â”€ mobile_integration/# Mobile app integration

# Phase 6: Monitoring & Maintenance (CRISP-ML(Q) + LLM Operations)
monitoring/                  # Continuous monitoring and maintenance
â”œâ”€â”€ performance/            # Model performance and drift monitoring
â”œâ”€â”€ data_quality/          # Ongoing data quality monitoring
â”œâ”€â”€ alerts/                # Alerting and notification systems
â”œâ”€â”€ maintenance/           # Model maintenance and retraining triggers
â”œâ”€â”€ feedback_loops/        # Feedback collection and incorporation
â”œâ”€â”€ lifecycle_management/   # Model lifecycle and retirement
â”œâ”€â”€ llm_monitoring/        # LLM-specific monitoring
â”‚   â”œâ”€â”€ token_usage/       # Token consumption tracking
â”‚   â”œâ”€â”€ latency_tracking/  # Response time monitoring
â”‚   â”œâ”€â”€ quality_monitoring/# Output quality assessment
â”‚   â”œâ”€â”€ safety_monitoring/ # Safety and alignment monitoring
â”‚   â””â”€â”€ cost_optimization/ # Cost tracking and optimization
â”œâ”€â”€ agent_monitoring/      # AI agent monitoring systems
â”‚   â”œâ”€â”€ task_tracking/     # Agent task execution tracking
â”‚   â”œâ”€â”€ goal_achievement/  # Goal completion monitoring
â”‚   â”œâ”€â”€ error_handling/    # Agent error detection and recovery
â”‚   â””â”€â”€ learning_metrics/  # Agent learning and improvement tracking
â””â”€â”€ user_feedback/         # User interaction and satisfaction monitoring
    â”œâ”€â”€ satisfaction/      # User satisfaction tracking
    â”œâ”€â”€ usage_patterns/    # Usage pattern analysis
    â”œâ”€â”€ feature_requests/  # Feature request management
    â””â”€â”€ issue_tracking/    # User issue and bug tracking

# Supporting Infrastructure
conf/                        # Configuration management and environment settings
â”œâ”€â”€ base/                   # Base configuration files
â”œâ”€â”€ local/                  # Local development overrides
â”œâ”€â”€ environments/           # Environment-specific configurations
â””â”€â”€ quality_gates/          # Quality assurance configurations

storage/                     # All storage operations (RAG, vector DBs, model storage, LLM data)
â”œâ”€â”€ vector_databases/       # Vector database operations for embeddings and semantic search
â”‚   â”œâ”€â”€ pinecone/          # Pinecone integration nodes
â”‚   â”œâ”€â”€ weaviate/          # Weaviate integration nodes
â”‚   â”œâ”€â”€ chroma/            # Chroma DB integration nodes
â”‚   â”œâ”€â”€ faiss/             # FAISS integration nodes
â”‚   â””â”€â”€ custom/            # Custom vector database implementations
â”œâ”€â”€ model_registry/         # Model versioning, storage, and retrieval
â”‚   â”œâ”€â”€ huggingface_hub/   # Hugging Face model hub integration
â”‚   â”œâ”€â”€ mlflow_registry/   # MLflow model registry
â”‚   â”œâ”€â”€ local_registry/    # Local model storage
â”‚   â””â”€â”€ cloud_registry/    # Cloud-based model storage
â”œâ”€â”€ embeddings/             # Store and retrieve embeddings for RAG and semantic applications
â”‚   â”œâ”€â”€ text_embeddings/   # Text embedding storage and retrieval
â”‚   â”œâ”€â”€ image_embeddings/  # Image embedding storage and retrieval
â”‚   â”œâ”€â”€ multimodal_embeddings/ # Multi-modal embedding storage
â”‚   â””â”€â”€ custom_embeddings/ # Custom embedding implementations
â”œâ”€â”€ feature_store/          # Feature store management and serving
â”œâ”€â”€ knowledge_graphs/       # Graph databases for constraints, relationships, and domain knowledge
â”‚   â”œâ”€â”€ neo4j/             # Neo4j graph database integration
â”‚   â”œâ”€â”€ rdf_stores/        # RDF triple store integration
â”‚   â””â”€â”€ property_graphs/   # Property graph implementations
â”œâ”€â”€ document_stores/        # Document storage for RAG and knowledge systems
â”‚   â”œâ”€â”€ elasticsearch/     # Elasticsearch document storage
â”‚   â”œâ”€â”€ mongodb/           # MongoDB document storage
â”‚   â”œâ”€â”€ postgres/          # PostgreSQL with document features
â”‚   â””â”€â”€ custom_stores/     # Custom document storage implementations
â”œâ”€â”€ conversation_memory/    # Conversation and session memory storage
â”‚   â”œâ”€â”€ short_term/        # Short-term memory implementations
â”‚   â”œâ”€â”€ long_term/         # Long-term memory implementations
â”‚   â”œâ”€â”€ semantic_memory/   # Semantic memory systems
â”‚   â””â”€â”€ episodic_memory/   # Episodic memory implementations
â””â”€â”€ cache/                  # Caching mechanisms for performance optimization
    â”œâ”€â”€ llm_cache/         # LLM response caching
    â”œâ”€â”€ embedding_cache/   # Embedding computation caching
    â”œâ”€â”€ retrieval_cache/   # Retrieval result caching
    â””â”€â”€ general_cache/     # General purpose caching

governance/                  # Compliance, audit, and policy management
â”œâ”€â”€ policies/               # Data governance and usage policies
â”œâ”€â”€ audit_trails/           # Audit logs and compliance tracking
â”œâ”€â”€ privacy/                # Privacy-preserving techniques and GDPR compliance
â”œâ”€â”€ risk_management/        # Risk assessment and mitigation strategies
â”œâ”€â”€ stakeholder_management/ # Stakeholder communication and approval workflows
â””â”€â”€ regulatory_compliance/  # Regulatory compliance (EU AI Act, FDA, etc.)

tests/                       # Comprehensive testing framework
â”œâ”€â”€ unit/                   # Unit tests for individual nodes
â”œâ”€â”€ integration/            # Integration tests for pipelines
â”œâ”€â”€ data_validation/        # Data quality and schema validation tests
â”œâ”€â”€ model_validation/       # Model performance and quality tests
â””â”€â”€ acceptance/             # User acceptance and stakeholder tests

docs/                        # Documentation and compliance records
â”œâ”€â”€ api/                    # API documentation
â”œâ”€â”€ tutorials/              # Usage examples and tutorials
â”œâ”€â”€ compliance/             # Regulatory compliance documentation
â”œâ”€â”€ architecture/           # System architecture documentation
â”œâ”€â”€ methodology/           # CRISP-ML(Q) process documentation
â””â”€â”€ stakeholder_reports/   # Reports for business stakeholders

utils/                       # Common utilities and helper functions
â”œâ”€â”€ data_helpers/           # Data manipulation and processing utilities
â”œâ”€â”€ model_helpers/          # Model-related utility functions
â”œâ”€â”€ io_helpers/             # Input/output operation helpers
â”œâ”€â”€ security_helpers/       # Security and encryption utilities
â”œâ”€â”€ nlp_helpers/            # NLP utilities for text processing and analysis
â”œâ”€â”€ graph_helpers/          # Graph database and knowledge graph utilities
â”œâ”€â”€ crisp_helpers/          # CRISP-DM/ML(Q) workflow utilities and phase transition managers
â”œâ”€â”€ llm_helpers/            # LLM integration and management utilities
â”‚   â”œâ”€â”€ api_clients/       # LLM API client utilities (OpenAI, Anthropic, etc.)
â”‚   â”œâ”€â”€ prompt_utils/      # Prompt engineering and optimization utilities
â”‚   â”œâ”€â”€ token_management/  # Token counting and management utilities
â”‚   â”œâ”€â”€ response_parsing/  # LLM response parsing and validation
â”‚   â””â”€â”€ cost_tracking/     # LLM usage cost tracking utilities
â”œâ”€â”€ langchain_helpers/      # LangChain integration and workflow utilities
â”‚   â”œâ”€â”€ chain_builders/    # Chain construction utilities
â”‚   â”œâ”€â”€ agent_utils/       # Agent management utilities
â”‚   â”œâ”€â”€ tool_integrations/ # Tool integration helpers
â”‚   â””â”€â”€ memory_utils/      # Memory and context management utilities
â”œâ”€â”€ huggingface_helpers/    # Hugging Face integration utilities
â”‚   â”œâ”€â”€ model_loaders/     # Model loading and management utilities
â”‚   â”œâ”€â”€ dataset_utils/     # Dataset processing utilities
â”‚   â”œâ”€â”€ tokenizer_utils/   # Tokenizer management utilities
â”‚   â””â”€â”€ pipeline_utils/    # Pipeline construction utilities
â”œâ”€â”€ rag_helpers/            # RAG system utilities and optimizations
â”‚   â”œâ”€â”€ retrieval_utils/   # Retrieval optimization utilities
â”‚   â”œâ”€â”€ chunking_utils/    # Document chunking and processing utilities
â”‚   â”œâ”€â”€ embedding_utils/   # Embedding generation and management utilities
â”‚   â””â”€â”€ fusion_utils/      # Multi-source information fusion utilities
â”œâ”€â”€ mcp_helpers/            # Model Context Protocol utilities
â”‚   â”œâ”€â”€ server_utils/      # MCP server development utilities
â”‚   â”œâ”€â”€ client_utils/      # MCP client integration utilities
â”‚   â”œâ”€â”€ protocol_utils/    # Protocol implementation utilities
â”‚   â””â”€â”€ discovery_utils/   # Tool discovery and registration utilities
â”œâ”€â”€ multimodal_helpers/     # Multi-modal AI utilities
â”‚   â”œâ”€â”€ vision_utils/      # Computer vision utilities
â”‚   â”œâ”€â”€ audio_utils/       # Audio processing utilities
â”‚   â”œâ”€â”€ text_vision_utils/ # Text-vision integration utilities
â”‚   â””â”€â”€ modality_fusion/   # Cross-modal fusion utilities
â””â”€â”€ agent_helpers/          # AI agent development utilities
    â”œâ”€â”€ planning_utils/    # Agent planning and reasoning utilities
    â”œâ”€â”€ execution_utils/   # Agent execution and control utilities
    â”œâ”€â”€ collaboration_utils/ # Multi-agent collaboration utilities
    â””â”€â”€ learning_utils/    # Agent learning and adaptation utilities
```

## ğŸ”„ Node-Based Architecture

Each directory contains **nodes** - reusable components that can be combined to build ML pipelines. Nodes follow consistent interfaces for easy composition and testing.

## ğŸ“ˆ Key Improvements from Industry Research & CRISP-ML(Q) + LLM/AI Alignment

- **CRISP-ML(Q) Structure**: Organized directories by CRISP-ML(Q) phases for systematic ML development
- **LLM/AI Integration**: Comprehensive support for modern AI applications including RAG, agents, and multi-modal systems
- **Business Understanding Integration**: Added dedicated `business_understanding/` and stakeholder management capabilities
- **Data Understanding Phase**: Dedicated `data_understanding/` with multi-modal analysis capabilities
- **LLM Application Framework**: Complete `llm_applications/` directory supporting prompts, agents, chains, tools, RAG, and MCP integration
- **Modern AI Patterns**: Support for LangChain, Hugging Face, RAG systems, AI agents, and Model Context Protocol
- **Quality Assurance Framework**: Integrated quality gates and stakeholder review processes throughout
- **Configuration Management**: Added `conf/` directory for centralized configuration following Kedro/MLflow patterns
- **Unified Evaluation**: Comprehensive evaluation framework with LLM-specific evaluation and stakeholder acceptance criteria
- **Security & Governance**: Enhanced with AI safety, responsible AI practices, and comprehensive compliance requirements
- **Testing Infrastructure**: Multi-layer testing framework supporting CRISP-ML(Q) validation requirements plus LLM evaluation
- **Documentation & Compliance**: Structured documentation supporting regulatory requirements and stakeholder communication
- **Monitoring & Maintenance**: Dedicated phase for continuous monitoring with LLM-specific tracking and feedback loops
- **Risk Management**: Integrated AI risk assessment and mitigation throughout the ML lifecycle
- **Multi-modal Support**: Complete support for text, image, audio, and cross-modal AI applications

## ğŸ¯ Design Principles (CRISP-ML(Q) + Modern AI Aligned)

- **Business-First**: Every component clearly supports business objectives and stakeholder requirements
- **AI-Native**: Built for modern LLM, RAG, agent, and multi-modal AI applications from the ground up
- **Iterative**: Support for CRISP-ML(Q)'s iterative and feedback-driven approach
- **Modularity**: Each node has a single responsibility within the CRISP-ML(Q) framework
- **Reusability**: Nodes can be used across different projects and CRISP-ML(Q) iterations
- **Scalability**: Easy to add new nodes and extend functionality within the methodology framework
- **Compliance-Ready**: Supports regulatory requirements and audit trails
- **Continuous Improvement**: Feedback loops and learning mechanisms embedded throughout
- **Framework-Agnostic**: Support for multiple AI frameworks (LangChain, Hugging Face, custom implementations)
- **Standards-Compliant**: Adherence to industry standards (MCP, scikit-learn interfaces, MLOps principles)
- **Performance-Optimized**: Built-in optimization for LLM costs, latency, and resource efficiency
- **Human-AI Collaboration**: Designed for seamless human-AI collaboration and oversight


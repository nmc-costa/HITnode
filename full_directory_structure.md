# ğŸ“ ML Full Directory Structure

This codebase follows a node-based architecture where each directory contains reusable nodes that can be composed into ML pipelines, organized according to CRISP-ML(Q) methodology with modern AI/LLM integration.

## ğŸ“ Directory Structure

```
# ğŸ“¥ Phase 1: Business & Data Understanding 
business_understanding/          # ğŸ“‹ Business: Business objectives and stakeholder requirements processing
â”œâ”€â”€ requirements/               # ğŸ¯ Business: NLP nodes to extract and embed stakeholder requirements from documents
â”œâ”€â”€ constraints/                # âš ï¸ Business: Nodes to parse technical/business constraints and create constraint graphs
â”œâ”€â”€ risk_assessment/            # ğŸ›¡ï¸ Business: Automated risk analysis nodes using NLP and rule-based systems
â”œâ”€â”€ success_metrics/            # ğŸ“Š Business: Nodes to extract and formalize business KPIs and success criteria
â”œâ”€â”€ stakeholder_analysis/       # ğŸ‘¥ Business: NLP nodes to analyze stakeholder communications and priorities
â”œâ”€â”€ domain_knowledge/           # ğŸ“š Business: Nodes to process domain-specific documents and create knowledge graphs
â””â”€â”€ context_extraction/         # ğŸ” Business: Extract and structure business context for LLM applications

data_understanding/              # ğŸ”¬ Analysis: Data exploration and automated analysis
â”œâ”€â”€ exploratory_analysis/       # ğŸ“ˆ Analysis: Automated EDA nodes with statistical profiling
â”œâ”€â”€ data_quality/               # âœ… Analysis: Data quality assessment and anomaly detection nodes (text, image, audio, video)
â”œâ”€â”€ statistics/                 # ğŸ“Š Analysis: Statistical analysis and distribution modeling nodes
â”œâ”€â”€ hypothesis_generation/      # ğŸ’¡ Analysis: NLP nodes to generate data-driven hypotheses from initial analysis
â”œâ”€â”€ semantic_analysis/          # ğŸ§  Analysis: Nodes to understand data semantics and relationships
â”œâ”€â”€ metadata_extraction/        # ğŸ·ï¸ Analysis: Automated metadata extraction and cataloging nodes
â””â”€â”€ multimodal_analysis/        # ğŸ­ Analysis: Analysis nodes for text, image, audio, and video data

# ğŸ›  Phase 2: Data Engineering (Data Preparation) 
datasets/                        # ğŸ“¥ Data I/O: ingestion, loading, and saving
â”œâ”€â”€ loaders/                    # ğŸ“‚ I/O: Load data from various sources (CSV, JSON, APIs, databases) and modalities
â”œâ”€â”€ savers/                     # ğŸ’¾ I/O: Save data to different formats and destinations
â”œâ”€â”€ extractors/                 # ğŸ”Œ I/O: Extract data from external systems and APIs
â”œâ”€â”€ validators/                 # âœ”ï¸ I/O: Data quality validation and schema checking
â”œâ”€â”€ huggingface_datasets/       # ğŸ¤— I/O: Hugging Face dataset integration and management
â””â”€â”€ multimodal_loaders/         # ğŸ­ I/O: Loaders for text, image, audio, video data

preprocessing/                   # ğŸ› ï¸ Data Transformations: Data cleaning, transformations, feature engineering
â”œâ”€â”€ cleaners/                   # ğŸ§¹ Transform: Data cleaning and quality improvement nodes
â”œâ”€â”€ transformers/               # ğŸ”„ Transform: Data type conversions and transformations
â”œâ”€â”€ feature_engineering/        # âš™ï¸ Transform: Feature creation, selection, and extraction
â”œâ”€â”€ normalizers/                # ğŸ“ Transform: Data normalization and scaling
â”œâ”€â”€ splitters/                  # âœ‚ï¸ Transform: Train/validation/test data splitting
â”œâ”€â”€ text_processors/            # ğŸ“ Transform: Text preprocessing for NLP and LLM applications
â”œâ”€â”€ tokenizers/                 # ğŸ”¤ Transform: Tokenization nodes for various models and frameworks
â”œâ”€â”€ chunking/                   # ğŸ“„ Transform: Chunking long text into smaller semantically meaningful "chunks"
â””â”€â”€ embeddings_prep/            # ğŸ¯ Transform: Prepare data for embedding generation

# ğŸ§  Phase 3: ML Model Engineering 
models/                          # ğŸ¤– ML Core: Training, fitting, prediction, and inference
â”œâ”€â”€ trainers/                   # ğŸ“ Training: Model training and fitting nodes
â”œâ”€â”€ predictors/                 # ğŸ”® Training: Prediction and inference nodes
â”œâ”€â”€ tuners/                     # ğŸ›ï¸ Training: Hyperparameter tuning and optimization
â”œâ”€â”€ architectures/              # ğŸ—ï¸ Training: Model architecture definitions and configurations
â”œâ”€â”€ ensembles/                  # ğŸ¤ Training: Ensemble methods and model combination
â”œâ”€â”€ registry/                   # ğŸ“¦ Training: Documenting ML model, versioning, experiments metadata
â”œâ”€â”€ huggingface_models/         # ğŸ¤— Training: Hugging Face model integration and fine-tuning
â”œâ”€â”€ llm_models/                 # ğŸ§  Training: Large language model implementations and wrappers
â”œâ”€â”€ embedding_models/           # ğŸ¯ Training: Embedding model implementations (text, image, multimodal)
â”œâ”€â”€ multimodal_models/          # ğŸ­ Training: Multi-modal AI models (vision-language, etc.)
â””â”€â”€ custom_architectures/       # ğŸ”§ Training: Custom neural network architectures

gpai_applications/               # ğŸ§  GPAI: Large Models powered applications components (LLMOPs, VLMOPs, Transformers, agents)
â”œâ”€â”€ prompts/                    # ğŸ’¬ GPAI: Prompt engineering and template management
â”‚   â”œâ”€â”€ templates/              # ğŸ“‹ GPAI: Reusable prompt templates
â”‚   â”œâ”€â”€ chains/                 # ğŸ”— GPAI: Prompt chaining strategies
â”‚   â”œâ”€â”€ few_shot/               # ğŸ¯ GPAI: Few-shot learning prompts
â”‚   â””â”€â”€ optimization/           # ğŸ›ï¸ GPAI: Prompt optimization and testing
â”œâ”€â”€ agents/                     # ğŸ¤– GPAI: AI agent implementations and workflows
â”‚   â”œâ”€â”€ autonomous/             # ğŸš€ GPAI: Autonomous agent systems
â”‚   â”œâ”€â”€ collaborative/          # ğŸ¤ GPAI: Multi-agent collaboration
â”‚   â”œâ”€â”€ tool_using/             # ğŸ› ï¸ GPAI: Tool-using agents
â”‚   â””â”€â”€ planning/               # ğŸ¯ GPAI: Agent planning and reasoning
â”œâ”€â”€ chains/                     # ğŸ”— GPAI: LangChain-style processing chains
â”‚   â”œâ”€â”€ sequential/             # â¡ï¸ GPAI: Sequential processing chains
â”‚   â”œâ”€â”€ parallel/               # âš¡ GPAI: Parallel processing chains
â”‚   â”œâ”€â”€ conditional/            # ğŸ”„ GPAI: Conditional logic chains
â”‚   â””â”€â”€ custom/                 # ğŸ”§ GPAI: Custom chain implementations
â”œâ”€â”€ tools/                      # ğŸ› ï¸ GPAI: AI tools and function calling
â”‚   â”œâ”€â”€ api_tools/              # ğŸ”Œ GPAI: API interaction tools
â”‚   â”œâ”€â”€ data_tools/             # ğŸ“Š GPAI: Data manipulation tools
â”‚   â”œâ”€â”€ search_tools/           # ğŸ” GPAI: Search and retrieval tools
â”‚   â””â”€â”€ custom_tools/           # ğŸ”§ GPAI: Custom tool implementations
â”œâ”€â”€ retrievers/                 # ğŸ” GPAI: Information retrieval systems
â”‚   â”œâ”€â”€ vector_search/          # ğŸ¯ GPAI: Vector-based retrieval
â”‚   â”œâ”€â”€ keyword_search/         # ğŸ”¤ GPAI: Traditional keyword search
â”‚   â”œâ”€â”€ hybrid_search/          # ğŸ”€ GPAI: Hybrid retrieval approaches
â”‚   â””â”€â”€ semantic_search/        # ğŸ§  GPAI: Semantic search implementations
â”œâ”€â”€ rag_systems/                # ğŸ“š GPAI: Retrieval Augmented Generation
â”‚   â”œâ”€â”€ retrievers/             # ğŸ” GPAI: RAG retrieval components
â”‚   â”œâ”€â”€ generators/             # ğŸ”® GPAI: RAG generation components
â”‚   â”œâ”€â”€ rankers/                # ğŸ† GPAI: Result ranking and reranking
â”‚   â”œâ”€â”€ fusion/                 # ğŸ”€ GPAI: Multi-source information fusion
â”‚   â””â”€â”€ evaluation/             # ğŸ“Š GPAI: RAG system evaluation
â”œâ”€â”€ context_management/         # ğŸ§  GPAI: Context handling and memory
â”‚   â”œâ”€â”€ memory/                 # ğŸ’¾ GPAI: Conversation and session memory
â”‚   â”œâ”€â”€ context_windows/        # ğŸ–¼ï¸ GPAI: Context window management
â”‚   â”œâ”€â”€ summarization/          # ğŸ“ GPAI: Context summarization strategies
â”‚   â””â”€â”€ retrieval/              # ğŸ” GPAI: Context retrieval mechanisms
â””â”€â”€ mcp_integration/            # ğŸ”Œ GPAI: Model Context Protocol integration
    â”œâ”€â”€ servers/                # ğŸ–¥ï¸ GPAI: MCP server implementations
    â”œâ”€â”€ clients/                # ğŸ’» GPAI: MCP client implementations
    â”œâ”€â”€ connectors/             # ğŸ”— GPAI: MCP connectors for various tools
    â””â”€â”€ protocols/              # ğŸ“¡ GPAI: Custom protocol implementations

# ğŸš€ Phase 4: ML Model Evaluation 
evaluation/                      # ğŸ“Š Assessment: Unified evaluation, metrics, and analysis
â”œâ”€â”€ metrics/                    # ğŸ“ˆ Assessment: Performance metrics (MAE, MSE, F1, AUC, NDCG, BLEU, ROUGE)
â”‚   â”œâ”€â”€ regression/             # ğŸ“Š Assessment: Regression metrics (MAE, MSE, RMSE, MAPE, RÂ²)
â”‚   â”œâ”€â”€ classification/         # ğŸ¯ Assessment: Classification metrics (accuracy, F1, precision, recall, AUC)
â”‚   â”œâ”€â”€ ranking/                # ğŸ† Assessment: Ranking metrics (NDCG, MAP, MRR)
â”‚   â””â”€â”€ custom/                 # ğŸ”§ Assessment: Business-specific and domain metrics
â”œâ”€â”€ scoring/                    # ğŸ¯ Assessment: Scoring predictions and business logic
â”‚   â”œâ”€â”€ thresholding/           # ğŸ“ Assessment: Threshold-based scoring and classification
â”‚   â”œâ”€â”€ ranking/                # ğŸ† Assessment: Ranking and percentile-based scoring
â”‚   â”œâ”€â”€ calibration/            # ğŸ›ï¸ Assessment: Probability calibration and confidence scoring
â”‚   â””â”€â”€ business_rules/         # ğŸ“‹ Assessment: Business logic and rule-based scoring
â”œâ”€â”€ validation/                 # âœ… Assessment: Cross-validation and model validation strategies
â”œâ”€â”€ testing/                    # ğŸ§ª Assessment: A/B testing and statistical testing nodes
â”œâ”€â”€ explainability/             # ğŸ” Assessment: Model interpretability (SHAP, LIME, feature importance)
â”œâ”€â”€ comparison/                 # âš–ï¸ Assessment: Model comparison and benchmarking
â”œâ”€â”€ quality_assurance/          # ğŸ›¡ï¸ Assessment: Quality gates and acceptance criteria
â”œâ”€â”€ stakeholder_review/         # ğŸ‘¥ Assessment: Stakeholder acceptance and sign-off
â”œâ”€â”€ reports/                    # ğŸ“‹ Assessment: Representations, plots, demos for different users
â”œâ”€â”€ llm_evaluation/             # ğŸ§  Assessment: LLM-specific evaluation methods
â”‚   â”œâ”€â”€ human_eval/             # ğŸ‘¥ Assessment: Human evaluation frameworks
â”‚   â”œâ”€â”€ automated_eval/         # ğŸ¤– Assessment: Automated evaluation systems
â”‚   â”œâ”€â”€ bias_testing/           # âš–ï¸ Assessment: Bias and fairness evaluation
â”‚   â”œâ”€â”€ safety_testing/         # ğŸ›¡ï¸ Assessment: AI safety and alignment testing
â”‚   â””â”€â”€ prompt_evaluation/      # ğŸ’¬ Assessment: Prompt effectiveness evaluation
â””â”€â”€ rag_evaluation/             # ğŸ“š Assessment: RAG system evaluation
    â”œâ”€â”€ retrieval_metrics/      # ğŸ” Assessment: Retrieval quality metrics
    â”œâ”€â”€ generation_metrics/     # ğŸ”® Assessment: Generation quality metrics
    â”œâ”€â”€ end_to_end/             # ğŸ”„ Assessment: End-to-end RAG evaluation
    â””â”€â”€ human_feedback/         # ğŸ‘¥ Assessment: Human feedback integration

# ğŸ­ Phase 5: Model Deployment 
deployment/                      # ğŸš€ Production: Production deployment and serving
â”œâ”€â”€ serving/                    # ğŸŒ Production: Real-time and batch serving endpoints, packaging, containers, Docker images
â”œâ”€â”€ infrastructure/             # ğŸ—ï¸ Production: Infrastructure as code and deployment configs
â”œâ”€â”€ user_interfaces/            # ğŸ‘¥ Production: Developer, partner, end user interfaces, StreamLit labs
â”œâ”€â”€ rollback/                   # â†©ï¸ Production: Rollback and recovery mechanisms
â”œâ”€â”€ security/                   # ğŸ”’ Production: Security configurations and access controls
â”œâ”€â”€ llm_serving/                # ğŸ§  Production: LLM-specific serving infrastructure
â”‚   â”œâ”€â”€ api_endpoints/          # ğŸ”Œ Production: LLM API endpoint implementations
â”‚   â”œâ”€â”€ streaming/              # ğŸŒŠ Production: Streaming response handling
â”‚   â”œâ”€â”€ batching/               # ğŸ“¦ Production: Batch processing systems
â”‚   â””â”€â”€ load_balancing/         # âš–ï¸ Production: Load balancing for LLM services
â”œâ”€â”€ agent_deployment/           # ğŸ¤– Production: AI agent deployment systems
â”‚   â”œâ”€â”€ orchestration/          # ğŸ­ Production: Agent orchestration platforms
â”‚   â”œâ”€â”€ workflow_engines/       # ğŸ”„ Production: Workflow execution engines
â”‚   â”œâ”€â”€ scheduling/             # ğŸ“… Production: Agent task scheduling
â”‚   â””â”€â”€ monitoring/             # ğŸ‘ï¸ Production: Agent performance monitoring
â””â”€â”€ edge_deployment/            # ğŸ“± Production: Edge and mobile deployment
    â”œâ”€â”€ optimization/           # ğŸ¯ Production: Model optimization for edge
    â”œâ”€â”€ quantization/           # ğŸ“ Production: Model quantization techniques
    â”œâ”€â”€ compression/            # ğŸ—œï¸ Production: Model compression methods
    â””â”€â”€ mobile_integration/     # ğŸ“± Production: Mobile app integration

# ğŸ”„ Phase 6: Monitoring & Maintenance 
monitoring/                      # ğŸ‘ï¸ Operations: Continuous monitoring and maintenance
â”œâ”€â”€ performance/                # ğŸ“Š Operations: Model performance and drift monitoring
â”œâ”€â”€ data_quality/               # âœ… Operations: Ongoing data quality monitoring
â”œâ”€â”€ alerts/                     # ğŸš¨ Operations: Alerting and notification systems
â”œâ”€â”€ maintenance/                # ğŸ”§ Operations: Model maintenance and retraining triggers
â”œâ”€â”€ feedback_loops/             # ğŸ”„ Operations: Feedback collection and incorporation
â”œâ”€â”€ lifecycle_management/       # ğŸ“Š Operations: Model lifecycle and retirement
â”œâ”€â”€ llm_monitoring/             # ğŸ§  Operations: LLM-specific monitoring
â”‚   â”œâ”€â”€ token_usage/            # ğŸ”¤ Operations: Token consumption tracking
â”‚   â”œâ”€â”€ latency_tracking/       # â±ï¸ Operations: Response time monitoring
â”‚   â”œâ”€â”€ quality_monitoring/     # âœ… Operations: Output quality assessment
â”‚   â”œâ”€â”€ safety_monitoring/      # ğŸ›¡ï¸ Operations: Safety and alignment monitoring
â”‚   â””â”€â”€ cost_optimization/      # ğŸ’° Operations: Cost tracking and optimization
â”œâ”€â”€ agent_monitoring/           # ğŸ¤– Operations: AI agent monitoring systems
â”‚   â”œâ”€â”€ task_tracking/          # ğŸ“‹ Operations: Agent task execution tracking
â”‚   â”œâ”€â”€ goal_achievement/       # ğŸ¯ Operations: Goal completion monitoring
â”‚   â”œâ”€â”€ error_handling/         # ğŸš¨ Operations: Agent error detection and recovery
â”‚   â””â”€â”€ learning_metrics/       # ğŸ“Š Operations: Agent learning and improvement tracking
â””â”€â”€ user_feedback/              # ğŸ‘¥ Operations: User interaction and satisfaction monitoring
    â”œâ”€â”€ satisfaction/           # ğŸ˜Š Operations: User satisfaction tracking
    â”œâ”€â”€ usage_patterns/         # ğŸ“ˆ Operations: Usage pattern analysis
    â”œâ”€â”€ feature_requests/       # ğŸ’¡ Operations: Feature request management
    â””â”€â”€ issue_tracking/         # ğŸ› Operations: User issue and bug tracking

# ğŸ§© Supporting Infrastructure
conf/                           # âš™ï¸ Config: Configuration management and environment settings
â”œâ”€â”€ base/                       # ğŸ—ï¸ Config: Base configuration files
â”œâ”€â”€ local/                      # ğŸ’» Config: Local development overrides
â”œâ”€â”€ environments/               # ğŸŒ Config: Environment-specific configurations
â”œâ”€â”€ datasets/                   # ğŸ“‹ Config: Data contracts, schemas
â””â”€â”€ quality_gates/              # ğŸ›¡ï¸ Config: Quality assurance configurations

tests/                          # ğŸ§ª Testing: Comprehensive testing framework
â”œâ”€â”€ unit/                       # ğŸ”¬ Testing: Unit tests for individual nodes
â”œâ”€â”€ integration/                # ğŸ”— Testing: Integration tests for pipelines
â”œâ”€â”€ data_validation/            # âœ… Testing: Data quality and schema validation tests
â”œâ”€â”€ model_validation/           # ğŸ¯ Testing: Model performance and quality tests
â””â”€â”€ acceptance/                 # ğŸ‘¥ Testing: User acceptance and stakeholder tests

data_acquisition/               # ğŸ“¡ Hardware: Acquisition of data and knowledge
â”œâ”€â”€ sensor_systems/             # ğŸ”Œ Hardware: Sensor hardware interfaces, communication, synchronization (ROS2)
â”œâ”€â”€ iot/                        # ğŸ“¶ Hardware: IoT communication and messaging (MQTT, brokers)
â”œâ”€â”€ kas/                        # ğŸ§  Hardware: Knowledge acquisition systems (ontologies, expert systems)
â””â”€â”€ experiment_designs/         # ğŸ”¬ Hardware: Design-of-experiments for algorithm comparisons, A/B tests

pipelines/                      # ğŸ”„ Orchestration: Automated deployment pipelines (node-pipeline frameworks)
â”œâ”€â”€ hinode/                     # ğŸ¯ Orchestration: HITnode framework pipelines (with README.md for usage)
â””â”€â”€ kedro/                      # ğŸ”§ Orchestration: Kedro framework pipelines (with README.md for usage)

storage/                        # ğŸ’¾ Data: All storage operations (RAG, vector DBs, model storage, LLM data)
â”œâ”€â”€ data/                       # ğŸ§ª Dev/Test: Locally temporary data folder that serves sample subsets to validate nodes
â”œâ”€â”€ vector_databases/           # ğŸ” Prod: Vector database operations for embeddings and semantic search
â”‚   â”œâ”€â”€ pinecone/               # ğŸŒ² Prod: Pinecone integration nodes
â”‚   â”œâ”€â”€ weaviate/               # ğŸ•¸ï¸ Prod: Weaviate integration nodes
â”‚   â”œâ”€â”€ chroma/                 # ğŸ¨ Prod: Chroma DB integration nodes
â”‚   â”œâ”€â”€ faiss/                  # ğŸ” Prod: FAISS integration nodes
â”‚   â””â”€â”€ custom/                 # ğŸ”§ Prod: Custom vector database implementations
â”œâ”€â”€ model_registry/             # ğŸ“¦ Prod: Model versioning, storage, and retrieval
â”‚   â”œâ”€â”€ huggingface_hub/        # ğŸ¤— Prod: Hugging Face model hub integration
â”‚   â”œâ”€â”€ mlflow_registry/        # ğŸ“Š Prod: MLflow model registry
â”‚   â”œâ”€â”€ local_registry/         # ğŸ’» Prod: Local model storage
â”‚   â””â”€â”€ cloud_registry/         # â˜ï¸ Prod: Cloud-based model storage
â”œâ”€â”€ embeddings/                 # ğŸ¯ Prod: Store and retrieve embeddings for RAG and semantic applications
â”‚   â”œâ”€â”€ text_embeddings/        # ğŸ“ Prod: Text embedding storage and retrieval
â”‚   â”œâ”€â”€ image_embeddings/       # ğŸ–¼ï¸ Prod: Image embedding storage and retrieval
â”‚   â”œâ”€â”€ multimodal_embeddings/  # ğŸ­ Prod: Multi-modal embedding storage
â”‚   â””â”€â”€ custom_embeddings/      # ğŸ”§ Prod: Custom embedding implementations
â”œâ”€â”€ feature_store/              # ğŸ“Š Prod: Feature store management and serving
â”œâ”€â”€ knowledge_graphs/           # ğŸ•¸ï¸ Prod: Graph databases for constraints, relationships, and domain knowledge
â”‚   â”œâ”€â”€ neo4j/                  # ğŸ”— Prod: Neo4j graph database integration
â”‚   â”œâ”€â”€ rdf_stores/             # ğŸ”— Prod: RDF triple store integration
â”‚   â””â”€â”€ property_graphs/        # ğŸ”— Prod: Property graph implementations
â”œâ”€â”€ document_stores/            # ğŸ“„ Prod: Document storage for RAG and knowledge systems
â”‚   â”œâ”€â”€ elasticsearch/          # ğŸ” Prod: Elasticsearch document storage
â”‚   â”œâ”€â”€ mongodb/                # ğŸƒ Prod: MongoDB document storage
â”‚   â”œâ”€â”€ postgres/               # ğŸ˜ Prod: PostgreSQL with document features
â”‚   â””â”€â”€ custom_stores/          # ğŸ”§ Prod: Custom document storage implementations
â”œâ”€â”€ conversation_memory/        # ğŸ§  Prod: Conversation and session memory storage
â”‚   â”œâ”€â”€ short_term/             # â±ï¸ Prod: Short-term memory implementations
â”‚   â”œâ”€â”€ long_term/              # ğŸ“… Prod: Long-term memory implementations
â”‚   â”œâ”€â”€ semantic_memory/        # ğŸ§  Prod: Semantic memory systems
â”‚   â””â”€â”€ episodic_memory/        # ğŸ“– Prod: Episodic memory implementations
â””â”€â”€ cache/                      # ğŸš€ Prod: Caching mechanisms for performance optimization
    â”œâ”€â”€ llm_cache/              # ğŸ§  Prod: LLM response caching
    â”œâ”€â”€ embedding_cache/        # ğŸ¯ Prod: Embedding computation caching
    â”œâ”€â”€ retrieval_cache/        # ğŸ” Prod: Retrieval result caching
    â””â”€â”€ general_cache/          # ğŸ”§ Prod: General purpose caching

governance/                     # ğŸ›¡ï¸ Compliance: Compliance, audit, and policy management
â”œâ”€â”€ policies/                   # ğŸ“‹ Compliance: Data governance and usage policies
â”œâ”€â”€ audit_trails/               # ğŸ“Š Compliance: Audit logs and compliance tracking
â”œâ”€â”€ privacy/                    # ğŸ”’ Compliance: Privacy-preserving techniques and GDPR compliance
â”œâ”€â”€ risk_management/            # âš ï¸ Compliance: Risk assessment and mitigation strategies
â”œâ”€â”€ stakeholder_management/     # ğŸ‘¥ Compliance: Stakeholder communication and approval workflows
â””â”€â”€ regulatory_compliance/      # ğŸ“‹ Compliance: Regulatory compliance (EU AI Act, FDA, etc.)

utils/                          # ğŸ”§ Utilities: Common utilities and helper functions
â”œâ”€â”€ data_helpers/               # ğŸ“Š Utilities: Data manipulation and processing utilities
â”œâ”€â”€ model_helpers/              # ğŸ¤– Utilities: Model-related utility functions
â”œâ”€â”€ io_helpers/                 # ğŸ“ Utilities: Input/output operation helpers
â”œâ”€â”€ security_helpers/           # ğŸ”’ Utilities: Security and encryption utilities
â”œâ”€â”€ nlp_helpers/                # ğŸ“ Utilities: NLP utilities for text processing and analysis
â”œâ”€â”€ graph_helpers/              # ğŸ•¸ï¸ Utilities: Graph database and knowledge graph utilities
â”œâ”€â”€ crisp_helpers/              # ğŸ“ Utilities: CRISP-DM/ML(Q) workflow utilities and phase transition managers
â”œâ”€â”€ llm_helpers/                # ğŸ§  Utilities: LLM integration and management utilities
â”‚   â”œâ”€â”€ api_clients/            # ğŸ”Œ Utilities: LLM API client utilities (OpenAI, Anthropic, etc.)
â”‚   â”œâ”€â”€ prompt_utils/           # ğŸ’¬ Utilities: Prompt engineering and optimization utilities
â”‚   â”œâ”€â”€ token_management/       # ğŸ”¤ Utilities: Token counting and management utilities
â”‚   â”œâ”€â”€ response_parsing/       # ğŸ“ Utilities: LLM response parsing and validation
â”‚   â””â”€â”€ cost_tracking/          # ğŸ’° Utilities: LLM usage cost tracking utilities
â”œâ”€â”€ langchain_helpers/          # ğŸ”— Utilities: LangChain integration and workflow utilities
â”‚   â”œâ”€â”€ chain_builders/         # ğŸ”— Utilities: Chain construction utilities
â”‚   â”œâ”€â”€ agent_utils/            # ğŸ¤– Utilities: Agent management utilities
â”‚   â”œâ”€â”€ tool_integrations/      # ğŸ› ï¸ Utilities: Tool integration helpers
â”‚   â””â”€â”€ memory_utils/           # ğŸ§  Utilities: Memory and context management utilities
â”œâ”€â”€ huggingface_helpers/        # ğŸ¤— Utilities: Hugging Face integration utilities
â”‚   â”œâ”€â”€ model_loaders/          # ğŸ“¦ Utilities: Model loading and management utilities
â”‚   â”œâ”€â”€ dataset_utils/          # ğŸ“Š Utilities: Dataset processing utilities
â”‚   â”œâ”€â”€ tokenizer_utils/        # ğŸ”¤ Utilities: Tokenizer management utilities
â”‚   â””â”€â”€ pipeline_utils/         # ğŸ”„ Utilities: Pipeline construction utilities
â”œâ”€â”€ rag_helpers/                # ğŸ“š Utilities: RAG system utilities and optimizations
â”‚   â”œâ”€â”€ retrieval_utils/        # ğŸ” Utilities: Retrieval optimization utilities
â”‚   â”œâ”€â”€ chunking_utils/         # ğŸ“„ Utilities: Document chunking and processing utilities
â”‚   â”œâ”€â”€ embedding_utils/        # ğŸ¯ Utilities: Embedding generation and management utilities
â”‚   â””â”€â”€ fusion_utils/           # ğŸ”€ Utilities: Multi-source information fusion utilities
â”œâ”€â”€ mcp_helpers/                # ğŸ”Œ Utilities: Model Context Protocol utilities
â”‚   â”œâ”€â”€ server_utils/           # ğŸ–¥ï¸ Utilities: MCP server development utilities
â”‚   â”œâ”€â”€ client_utils/           # ğŸ’» Utilities: MCP client integration utilities
â”‚   â”œâ”€â”€ protocol_utils/         # ğŸ“¡ Utilities: Protocol implementation utilities
â”‚   â””â”€â”€ discovery_utils/        # ğŸ” Utilities: Tool discovery and registration utilities
â”œâ”€â”€ multimodal_helpers/         # ğŸ­ Utilities: Multi-modal AI utilities
â”‚   â”œâ”€â”€ vision_utils/           # ğŸ‘ï¸ Utilities: Computer vision utilities
â”‚   â”œâ”€â”€ audio_utils/            # ğŸ”Š Utilities: Audio processing utilities
â”‚   â”œâ”€â”€ text_vision_utils/      # ğŸ“ğŸ‘ï¸ Utilities: Text-vision integration utilities
â”‚   â””â”€â”€ modality_fusion/        # ğŸ”€ Utilities: Cross-modal fusion utilities
â””â”€â”€ agent_helpers/              # ğŸ¤– Utilities: AI agent development utilities
    â”œâ”€â”€ planning_utils/         # ğŸ¯ Utilities: Agent planning and reasoning utilities
    â”œâ”€â”€ execution_utils/        # ğŸš€ Utilities: Agent execution and control utilities
    â”œâ”€â”€ collaboration_utils/    # ğŸ¤ Utilities: Multi-agent collaboration utilities
    â””â”€â”€ learning_utils/         # ğŸ“Š Utilities: Agent learning and adaptation utilities

docs/                           # ğŸ“š Documentation: Documentation and compliance records
â”œâ”€â”€ api/                        # ğŸ”Œ Docs: API documentation
â”œâ”€â”€ tutorials/                  # ğŸ“– Docs: Usage examples and tutorials
â”œâ”€â”€ compliance/                 # ğŸ“‹ Docs: Regulatory compliance documentation
â”œâ”€â”€ architecture/               # ğŸ—ï¸ Docs: System architecture documentation
â”œâ”€â”€ methodology/                # ğŸ“ Docs: CRISP-ML(Q) process documentation
â””â”€â”€ stakeholder_reports/        # ğŸ‘¥ Docs: Reports for business stakeholders
```

## ğŸ”„ Node-Based Architecture

Each directory contains **nodes** - reusable components that can be combined to build ML pipelines. Nodes follow consistent interfaces for easy composition and testing.

## ğŸ·ï¸ Custom [Crisp-ML](https://ml-ops.org/content/crisp-ml) table

| Activities | Subactivities and Description |
|---|---|
| **Business and Data Understanding** | - Define business objectives: requirements, constraints, success_metrics<br>- Translate business objectives into ML objectives<br>- Collect and verify data<br>- Assess the project feasibility<br>- Annotations if supervised<br>- Create POCs<br>- **GenAI:** Define generative use case (e.g., summarization, content creation) and success criteria (e.g., coherence, factuality)<br>- **Agents:** Define agent's goals, available tools (APIs, functions), and task completion metrics |
| **Data Engineering (data preparation)** | - Feature selection<br>- Data selection<br>- Class balancing<br>- Cleaning data (noise reduction, data imputation)<br>- Feature engineering (data construction)<br>- Data augmentation<br>- Data standartization<br>- **GenAI:** Curate instruction datasets for fine-tuning<br>- **GenAI (RAG):** Build and process a knowledge base for Retrieval-Augmented Generation (chunking, embedding)<br>- **Agents:** Prepare tool documentation and few-shot examples for the agent to learn from |
| **ML Model Engineering** | - Define quality measure of the model<br>- ML algorithm selection (baseline selection)<br>- Adding domain knowledge to specialize the model<br>- Model training<br>- Optional: applying trainsfer learning (using pre-trained models)<br>- Model compression<br>- Ensemble learning<br>- Model Registry: Documenting the ML model and experiments<br>- **GenAI:** Select a base Foundation Model (FM)<br>- **GenAI:** Develop system through prompt engineering, fine-tuning (e.g., LoRA), or RAG<br>- **Agents:** Design and implement the agent's reasoning loop (e.g., ReAct) and tool-use mechanisms |
| **ML Model Evaluation** | - Validate model's performance<br>- Determine robustess<br>- Increase model's explainability<br>- Make a decision whether to deploy the model<br>- Document the evaluation phase<br>- **GenAI:** Evaluate for hallucinations, toxicity, and bias (Red Teaming)<br>- **GenAI:** Use LLM-as-a-judge or human feedback (RLHF) for qualitative assessment<br>- **Agents:** Evaluate task completion success rate and tool selection accuracy |
| **Model Deployment** | - Evaluate model under production condition<br>- Assure user acceptance and usability<br>- Model governance<br>- Deploy according to the selected strategy (A/B testing, multi-armed bandits)<br>- **GenAI (RAG):** Deploy the vector database and retrieval system alongside the LLM<br>- **Agents:** Deploy the agent's reasoning engine with secure access to its tools/APIs |
| **Model Monitoring and Maintenance** | - Monitor the efficiency and efficacy of the model prediction serving<br>- Compare to the previously specified success criteria (thresholds)<br>- Retrain model if required<br>- Collect new data<br>- Perform labelling of the new data points<br>- Repeat tasks from the Model Engineering and Model Evaluation phases<br>- Continuous, integration, training, and deployment of the model<br>- **GenAI:** Monitor for prompt injection, PII leakage, and concept drift in the knowledge base<br>- **Agents:** Monitor task success rates, tool errors, and conversation logs for failures |

## ğŸ“ˆ Key Improvements from Industry Research & CRISP-ML(Q) + LLM/AI Alignment

- **CRISP-ML(Q) Structure**: Organized directories by CRISP-ML(Q) phases for systematic ML development
- **Business Understanding Integration**: Added dedicated `business_understanding/` and stakeholder management capabilities
- **Data Understanding Phase**: Dedicated `data_understanding/` with multi-modal analysis capabilities
- **GPAI (LLM/AI) Integration**: Comprehensive support for modern AI applications including RAG, agents, and multi-modal systems
- **GPAI Application Framework**: Complete `gpai_applications/` directory supporting prompts, agents, chains, tools, RAG, and MCP integration
- **Modern AI Patterns**: Support for LangChain, Hugging Face, RAG systems, AI agents, and Model Context Protocol
- **Quality Assurance Framework**: Integrated quality gates and stakeholder review processes throughout
- **Configuration Management**: Added `conf/` directory for centralized configuration following Kedro/MLflow patterns
- **Unified Evaluation**: Comprehensive evaluation framework with LLM-specific evaluation and stakeholder acceptance criteria
- **Security & Governance**: Enhanced with AI safety, responsible AI practices, and comprehensive compliance requirements
- **Testing Infrastructure**: Multi-layer testing framework supporting CRISP-ML(Q) validation requirements plus LLM evaluation
- **Documentation & Compliance**: Structured documentation supporting regulatory requirements and stakeholder communication
- **Monitoring & Maintenance**: Dedicated phase for continuous monitoring with LLM-specific tracking and feedback loops
- **Risk Management**: Integrated AI risk assessment and mitigation throughout the ML lifecycle
- **Multi-modal Support**: Complete support for text, image, audio, and cross-modal AI applications
- **Hardware Integration**: Added `data_acquisition/` for sensor systems, IoT, and knowledge acquisition systems
- **Pipeline Orchestration**: Dedicated `pipelines/` directory with support for multiple frameworks (HITnode, Kedro)

## ğŸ¯ Design Principles (CRISP-ML(Q) + Modern AI Aligned)

- **Business-First**: Every component clearly supports business objectives and stakeholder requirements
- **AI-Native**: Built for modern LLM, RAG, agent, and multi-modal AI applications from the ground up
- **Iterative**: Support for CRISP-ML(Q)'s iterative and feedback-driven approach
- **Modularity**: Each node has a single responsibility within the CRISP-ML(Q) framework
- **Reusability**: Nodes can be used across different projects and CRISP-ML(Q) iterations
- **Scalability**: Easy to add new nodes and extend functionality within the methodology framework
- **Compliance-Ready**: Supports regulatory requirements and audit trails
- **Continuous Improvement**: Feedback loops and learning mechanisms embedded throughout
- **Framework-Agnostic**: Support for multiple AI frameworks (LangChain, Hugging Face, custom implementations)
- **Standards-Compliant**: Adherence to industry standards (MCP, scikit-learn interfaces, MLOps principles)
- **Performance-Optimized**: Built-in optimization for LLM costs, latency, and resource efficiency
- **Human-AI Collaboration**: Designed for seamless human-AI collaboration and oversight

## ğŸ·ï¸ Emoji Categorization

**Each directory is clearly marked with emojis indicating its purpose:**

```
ğŸ“‹ Business: Business logic and requirements
ğŸ”¬ Analysis: Data analysis and exploration
ğŸ“¥ I/O: Input/output operations
ğŸ› ï¸ Transform: Data transformation and processing
ğŸ¤– Training: Model training and development
ğŸ§  GPAI: Generative AI and LLM components
ğŸ“Š Assessment: Evaluation and metrics
ğŸš€ Production: Production deployment and serving
ğŸ‘ï¸ Operations: Monitoring and maintenance
ğŸ’¾ Data: Data storage and persistence
ğŸ“¡ Hardware: Hardware interfaces and acquisition
ğŸ”„ Orchestration: Pipeline orchestration
ğŸ”§ Utilities: Helper functions and utilities
âš™ï¸ Config: Configuration management
ğŸ§ª Testing: Quality assurance and testing
ğŸ“š Documentation: Documentation and compliance
ğŸ›¡ï¸ Compliance: Governance and regulatory compliance
ğŸ§ª Dev/Test: Development and testing components
ğŸŒ Prod: Production systems and operations
```

